{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Sequence to Sequence - Article Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T03:04:22.643999Z",
     "start_time": "2019-06-21T03:04:22.633771Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T04:37:35.830305Z",
     "start_time": "2019-06-21T04:37:35.498103Z"
    }
   },
   "outputs": [],
   "source": [
    "path = './'\n",
    "vocab = pickle.load(open(path + 'vocab_new.pkl', \"rb\" ))\n",
    "inv_vocab = pickle.load(open(path + 'inv_vocab_new.pkl', \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-21T04:37:59.071Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>text_length</th>\n",
       "      <th>summ_length</th>\n",
       "      <th>compression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, ...</td>\n",
       "      <td>[1, 16, 31, 20, 21, 22, 23, 24, 25, 150, 68, 1...</td>\n",
       "      <td>728</td>\n",
       "      <td>23</td>\n",
       "      <td>31.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 164, 338, 339, 340, 163, 61, 90, 341, 97, ...</td>\n",
       "      <td>[1, 164, 338, 339, 340, 354, 355, 262, 16, 52,...</td>\n",
       "      <td>409</td>\n",
       "      <td>28</td>\n",
       "      <td>14.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 8, 407, 7, 59, 482, 483, 484, 485, 132, 48...</td>\n",
       "      <td>[1, 528, 630, 8, 407, 7, 59, 482, 483, 484, 48...</td>\n",
       "      <td>404</td>\n",
       "      <td>19</td>\n",
       "      <td>21.263158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 631, 632, 385, 633, 75, 634, 47, 635, 636,...</td>\n",
       "      <td>[1, 752, 760, 711, 761, 762, 763, 767, 768, 97...</td>\n",
       "      <td>705</td>\n",
       "      <td>26</td>\n",
       "      <td>27.115385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 917, 918, 919, 41, 16, 920, 921, 427, 110,...</td>\n",
       "      <td>[1, 917, 918, 919, 41, 16, 920, 90, 853, 127, ...</td>\n",
       "      <td>708</td>\n",
       "      <td>21</td>\n",
       "      <td>33.714286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  [1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, ...   \n",
       "1  [1, 164, 338, 339, 340, 163, 61, 90, 341, 97, ...   \n",
       "2  [1, 8, 407, 7, 59, 482, 483, 484, 485, 132, 48...   \n",
       "3  [1, 631, 632, 385, 633, 75, 634, 47, 635, 636,...   \n",
       "4  [1, 917, 918, 919, 41, 16, 920, 921, 427, 110,...   \n",
       "\n",
       "                                             summary  text_length  \\\n",
       "0  [1, 16, 31, 20, 21, 22, 23, 24, 25, 150, 68, 1...          728   \n",
       "1  [1, 164, 338, 339, 340, 354, 355, 262, 16, 52,...          409   \n",
       "2  [1, 528, 630, 8, 407, 7, 59, 482, 483, 484, 48...          404   \n",
       "3  [1, 752, 760, 711, 761, 762, 763, 767, 768, 97...          705   \n",
       "4  [1, 917, 918, 919, 41, 16, 920, 90, 853, 127, ...          708   \n",
       "\n",
       "   summ_length  compression  \n",
       "0           23    31.652174  \n",
       "1           28    14.607143  \n",
       "2           19    21.263158  \n",
       "3           26    27.115385  \n",
       "4           21    33.714286  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './'\n",
    "train_df = pickle.load(open(path + 'train_df_new.pkl', \"rb\"))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>text_length</th>\n",
       "      <th>summ_length</th>\n",
       "      <th>compression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 141, 27985, 1907, 4217, 718, 1538, 1060, 1...</td>\n",
       "      <td>[1, 1060, 1184, 9781, 781, 8153, 12564, 3858, ...</td>\n",
       "      <td>516</td>\n",
       "      <td>32</td>\n",
       "      <td>16.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 47, 52, 1318, 10385, 6517, 12543, 16, 694,...</td>\n",
       "      <td>[1, 12543, 1186, 712, 10511, 8110, 145, 320, 9...</td>\n",
       "      <td>565</td>\n",
       "      <td>17</td>\n",
       "      <td>33.235294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 70, 16, 23828, 3437, 28360, 14235, 145, 29...</td>\n",
       "      <td>[1, 41, 320, 1956, 9097, 551, 4208, 628, 2325,...</td>\n",
       "      <td>484</td>\n",
       "      <td>28</td>\n",
       "      <td>17.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 43, 399, 1594, 6502, 19817, 90, 390, 1841,...</td>\n",
       "      <td>[1, 16, 339, 551, 1367, 12088, 1956, 5600, 487...</td>\n",
       "      <td>367</td>\n",
       "      <td>16</td>\n",
       "      <td>22.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 1546, 4998, 78, 16, 13929, 11574, 5272, 91...</td>\n",
       "      <td>[1, 16, 17219, 90, 907, 551, 526, 7297, 1080, ...</td>\n",
       "      <td>443</td>\n",
       "      <td>36</td>\n",
       "      <td>12.305556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  [1, 141, 27985, 1907, 4217, 718, 1538, 1060, 1...   \n",
       "1  [1, 47, 52, 1318, 10385, 6517, 12543, 16, 694,...   \n",
       "2  [1, 70, 16, 23828, 3437, 28360, 14235, 145, 29...   \n",
       "3  [1, 43, 399, 1594, 6502, 19817, 90, 390, 1841,...   \n",
       "4  [1, 1546, 4998, 78, 16, 13929, 11574, 5272, 91...   \n",
       "\n",
       "                                             summary  text_length  \\\n",
       "0  [1, 1060, 1184, 9781, 781, 8153, 12564, 3858, ...          516   \n",
       "1  [1, 12543, 1186, 712, 10511, 8110, 145, 320, 9...          565   \n",
       "2  [1, 41, 320, 1956, 9097, 551, 4208, 628, 2325,...          484   \n",
       "3  [1, 16, 339, 551, 1367, 12088, 1956, 5600, 487...          367   \n",
       "4  [1, 16, 17219, 90, 907, 551, 526, 7297, 1080, ...          443   \n",
       "\n",
       "   summ_length  compression  \n",
       "0           32    16.125000  \n",
       "1           17    33.235294  \n",
       "2           28    17.285714  \n",
       "3           16    22.937500  \n",
       "4           36    12.305556  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './'\n",
    "dev_df = pickle.load(open(path + 'val_df_new.pkl', \"rb\"))\n",
    "dev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T04:01:42.896751Z",
     "start_time": "2019-06-21T04:01:42.892838Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_df.text[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-20T20:59:18.608736Z",
     "start_time": "2019-06-20T20:59:18.605224Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11282\n",
      "backpack\n"
     ]
    }
   ],
   "source": [
    "print(vocab['backpack'])\n",
    "print(inv_vocab[11282])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107447"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(count    190802.000000\n",
       " mean        474.481745\n",
       " std         122.320603\n",
       " min         119.000000\n",
       " 25%         374.000000\n",
       " 50%         465.000000\n",
       " 75%         573.000000\n",
       " max        1289.000000\n",
       " Name: text, dtype: float64, count    190802.000000\n",
       " mean         24.302513\n",
       " std           5.304360\n",
       " min           6.000000\n",
       " 25%          20.000000\n",
       " 50%          24.000000\n",
       " 75%          28.000000\n",
       " max          49.000000\n",
       " Name: summary, dtype: float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating Text and Summary lengths for train dataset\n",
    "train_text_lens = train_df.text.map(lambda x: len(x))\n",
    "train_summary_lens = train_df.summary.map(lambda x: len(x))\n",
    "train_text_lens.describe(), train_summary_lens.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90861, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering down train dataset\n",
    "train_df = train_df[(train_text_lens > 374) &\n",
    "                    (train_text_lens < 573) & \n",
    "                    (train_summary_lens < 50) & \n",
    "                    (train_summary_lens > 16)]\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(count    20892.000000\n",
       " mean       474.069500\n",
       " std        122.335284\n",
       " min        166.000000\n",
       " 25%        373.000000\n",
       " 50%        465.000000\n",
       " 75%        573.000000\n",
       " max       1144.000000\n",
       " Name: text, dtype: float64, count    20892.000000\n",
       " mean        24.262062\n",
       " std          5.283030\n",
       " min          7.000000\n",
       " 25%         20.000000\n",
       " 50%         24.000000\n",
       " 75%         28.000000\n",
       " max         46.000000\n",
       " Name: summary, dtype: float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating Text and Summary lengths for validation dataset\n",
    "dev_text_lens = dev_df.text.map(lambda x: len(x))\n",
    "dev_summary_lens = dev_df.summary.map(lambda x: len(x))\n",
    "dev_text_lens.describe(), dev_summary_lens.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9903, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering down validation dataset on same conditions as train\n",
    "dev_df = dev_df[(dev_text_lens > 374) &\n",
    "                (dev_text_lens < 573) & \n",
    "                (dev_summary_lens < 50) & \n",
    "                (dev_summary_lens > 16)]\n",
    "dev_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1289, 49)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_length_text = train_text_lens.max()\n",
    "max_seq_length_summ = train_summary_lens.max()\n",
    "max_seq_length_text, max_seq_length_summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[:, 'text'] = train_df['text'].apply(lambda x: ((max_seq_length_text - len(x)) * [0]) + x)\n",
    "train_df.loc[:, 'summary'] = train_df['summary'].apply(lambda x: (x + (max_seq_length_summ - len(x)) * [0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df.loc[:, 'text'] = dev_df['text'].apply(lambda x: np.array((max_seq_length_text - len(x)) * [0] + x))\n",
    "dev_df.loc[:, 'summary'] = dev_df['summary'].apply(lambda x: np.array(x + (max_seq_length_summ - len(x)) * [0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>text_length</th>\n",
       "      <th>summ_length</th>\n",
       "      <th>compression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1060, 1184, 9781, 781, 8153, 12564, 3858, ...</td>\n",
       "      <td>516</td>\n",
       "      <td>32</td>\n",
       "      <td>16.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 41, 320, 1956, 9097, 551, 4208, 628, 2325,...</td>\n",
       "      <td>484</td>\n",
       "      <td>28</td>\n",
       "      <td>17.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 16, 17219, 90, 907, 551, 526, 7297, 1080, ...</td>\n",
       "      <td>443</td>\n",
       "      <td>36</td>\n",
       "      <td>12.305556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 551, 6746, 12779, 267, 262, 327, 73, 628, ...</td>\n",
       "      <td>438</td>\n",
       "      <td>21</td>\n",
       "      <td>20.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 13640, 262, 10200, 50165, 385, 10470, 47, ...</td>\n",
       "      <td>435</td>\n",
       "      <td>31</td>\n",
       "      <td>14.032258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "6  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "8  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                             summary  text_length  \\\n",
       "0  [1, 1060, 1184, 9781, 781, 8153, 12564, 3858, ...          516   \n",
       "2  [1, 41, 320, 1956, 9097, 551, 4208, 628, 2325,...          484   \n",
       "4  [1, 16, 17219, 90, 907, 551, 526, 7297, 1080, ...          443   \n",
       "6  [1, 551, 6746, 12779, 267, 262, 327, 73, 628, ...          438   \n",
       "8  [1, 13640, 262, 10200, 50165, 385, 10470, 47, ...          435   \n",
       "\n",
       "   summ_length  compression  \n",
       "0           32    16.125000  \n",
       "2           28    17.285714  \n",
       "4           36    12.305556  \n",
       "6           21    20.857143  \n",
       "8           31    14.032258  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T04:30:15.335690Z",
     "start_time": "2019-06-21T04:30:15.331289Z"
    }
   },
   "outputs": [],
   "source": [
    "class SummarizationDataset(Dataset):\n",
    "    def __init__(self, df): #pairs, input_lang, output_lang):\n",
    "#         self.df = df\n",
    "        self.article = df.text.values\n",
    "        self.summary = df.summary.values\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.article)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = np.array(self.article[idx])\n",
    "        y = np.array(self.summary[idx])\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T04:30:16.331393Z",
     "start_time": "2019-06-21T04:30:16.328775Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds = SummarizationDataset(train_df)\n",
    "valid_ds = SummarizationDataset(dev_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset/DataLoader Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T04:30:16.517551Z",
     "start_time": "2019-06-21T04:30:16.514012Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1, 1180, 1184, 1185, 1186,  208, 1187, 1188,   43,   16, 1189,\n",
       "       1190,  198,  327,   47, 1191,   83, 1192, 1193,  570, 1194, 1195,\n",
       "       1196, 1197, 1198, 1199, 1200,  163,   16,    2,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T04:30:17.008644Z",
     "start_time": "2019-06-21T04:30:16.990744Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size=5\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T04:30:17.492115Z",
     "start_time": "2019-06-21T04:30:17.428387Z"
    }
   },
   "outputs": [],
   "source": [
    "arts, summs = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T04:30:18.217978Z",
     "start_time": "2019-06-21T04:30:18.214074Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 1289]), torch.Size([5, 49]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arts.shape, summs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[   0,    0,    0,  ..., 1087, 2019,    2],\n",
       "         [   0,    0,    0,  ...,   18, 2459,    2],\n",
       "         [   0,    0,    0,  ..., 3851, 5151,    2],\n",
       "         [   0,    0,    0,  ...,   16, 3383,    2],\n",
       "         [   0,    0,    0,  ...,   18, 4170,    2]]),\n",
       " tensor([[     1,    551,   1409,    512,     16,  34290,   2380,    145,     68,\n",
       "             818,    141,   4017,  12812,   1391,  13891,    816,    311,    366,\n",
       "               2,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0],\n",
       "         [     1,     43,    864,    908,    327, 104295,   1300,   2387,    512,\n",
       "            5309,    192,   1218,     70,   1615,  30079,   2460,   2906,    171,\n",
       "            2607,   6419,    598,     43,  11587,   6664,  10832,     47,   1365,\n",
       "            4719,     41,   1350,      2,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0],\n",
       "         [     1,   4505,   4506,  10974,    551,  26697,  10630,   1053,    570,\n",
       "            1200,  12753,   1697,    642,  10512,     73,    344,   5998,      2,\n",
       "               0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0],\n",
       "         [     1,     16,   2596,   6384,  13077,    398,      8,     34,   1018,\n",
       "              16,   2044,   3122,   1053,    131,    614,     59,    624,     20,\n",
       "              43,     16,     63,     16,   7275,     16,     65,    333,   2146,\n",
       "             260,     59,      2,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0],\n",
       "         [     1,  49910,   1651,   2478,      8,   6987,   8835,  22949,   9751,\n",
       "             882,  51065,   2412,  25479,     16,   1576,     47,     16,   2221,\n",
       "             118,   1951,  13932,    117,   6926,      2,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0]]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arts, summs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Seq2Seq Model\n",
    "\n",
    "A Recurrent Neural Network, or RNN, is a network that operates on a\n",
    "sequence and uses its own output as input for subsequent steps.\n",
    "\n",
    "A `Sequence to Sequence network <https://arxiv.org/abs/1409.3215>`__, or\n",
    "seq2seq network, or `Encoder Decoder\n",
    "network <https://arxiv.org/pdf/1406.1078v3.pdf>`__, is a model\n",
    "consisting of two RNNs called the encoder and decoder. The encoder reads\n",
    "an input sequence and outputs a single vector, and the decoder reads\n",
    "that vector to produce an output sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Encoder\n",
    "\n",
    "The encoder of a seq2seq network is a RNN that outputs some value for\n",
    "every word from the input sentence. For every input word the encoder\n",
    "outputs a vector and a hidden state, and uses the hidden state for the\n",
    "next input word.\n",
    "\n",
    "![](imgs/encoder-network.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "word2vec_path = '~/GoogleNews-vectors-negative300.bin'\n",
    "word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_matrix(word_vecs, inv_vocab, D=300):\n",
    "    \"\"\"Creates embedding matrix from word vectors. \"\"\"\n",
    "    V = len(inv_vocab)\n",
    "    W = np.random.randn(V, D)\n",
    "\n",
    "    for i in range(V):\n",
    "        if inv_vocab[i] in word_vecs:\n",
    "            W[i] = word_vecs[inv_vocab[i]]\n",
    "\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00402832, -0.24707031,  0.09814453, ...,  0.1640625 ,\n",
       "         0.24023438,  0.6875    ],\n",
       "       [-0.19433594, -0.05932617, -0.18066406, ..., -0.12988281,\n",
       "        -0.15527344,  0.14941406],\n",
       "       [-0.15039062, -0.03063965,  0.02770996, ...,  0.11132812,\n",
       "         0.06225586,  0.04003906],\n",
       "       ...,\n",
       "       [-0.08984375, -0.16210938,  0.08251953, ..., -0.01513672,\n",
       "        -0.03039551,  0.14550781],\n",
       "       [ 0.06591797,  0.140625  , -0.09619141, ...,  0.05761719,\n",
       "         0.12255859,  0.16796875],\n",
       "       [ 0.02526855,  0.24804688,  0.08349609, ...,  0.02160645,\n",
       "         0.11181641,  0.01239014]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = 300\n",
    "\n",
    "emb_matrix = create_embedding_matrix(word2vec, inv_vocab, embedding_dim)\n",
    "emb_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107447, 300)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T04:34:29.831839Z",
     "start_time": "2019-06-21T04:34:29.826612Z"
    }
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, embedding_matrix):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.embeddings.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
    "        self.embeddings.weight.requires_grad = False\n",
    "        self.gru = nn.GRU(hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        output, hidden = self.gru(x)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The  Decoder\n",
    "   -----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, embedding_matrix):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.embeddings.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
    "        self.embeddings.weight.requires_grad = False\n",
    "        self.gru = nn.GRU(hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        embedded = self.embeddings(x)\n",
    "        embedded = self.dropout(embedded)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        output = self.out(hidden[-1]) # output is a function of the hidden, what we are comparing to the y\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T04:34:31.452711Z",
     "start_time": "2019-06-21T04:34:31.010817Z"
    }
   },
   "outputs": [],
   "source": [
    "input_size = len(vocab)\n",
    "hidden_size = 300\n",
    "encoder = EncoderRNN(input_size, embedding_dim, hidden_size, emb_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T04:34:32.214942Z",
     "start_time": "2019-06-21T04:34:31.454466Z"
    }
   },
   "outputs": [],
   "source": [
    "enc_outputs, enc_hidden = encoder(arts.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T04:35:20.535689Z",
     "start_time": "2019-06-21T04:35:20.521276Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0005, -0.0833, -0.0856,  ..., -0.0276,  0.1284,  0.0565],\n",
       "        [ 0.0226, -0.1819, -0.1398,  ..., -0.0573,  0.1693,  0.0593],\n",
       "        [ 0.0063, -0.1936, -0.1692,  ..., -0.0806,  0.0995,  0.0564],\n",
       "        ...,\n",
       "        [ 0.0694, -0.0193,  0.0985,  ...,  0.0370,  0.1077, -0.1241],\n",
       "        [ 0.0073,  0.0551,  0.0967,  ...,  0.0359,  0.0728, -0.0816],\n",
       "        [ 0.0307,  0.0716,  0.0371,  ...,  0.0131,  0.0945, -0.0470]],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_outputs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SOS_token = 1\n",
    "batch_size = summs.size(0)\n",
    "decoder_input = SOS_token*torch.ones(batch_size,1).long()\n",
    "decoder_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = len(vocab)\n",
    "hidden_dim = 300\n",
    "decoder = DecoderRNN(output_size, embedding_dim, hidden_dim, emb_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, hidden = decoder(decoder_input, enc_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 5, 300]), torch.Size([5, 107447]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden.shape, output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training\n",
    "========"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rouge_format(arr):\n",
    "    sents = []\n",
    "    for l in arr:\n",
    "        sent = []\n",
    "        for n in l:\n",
    "            if n not in (0,1,2):\n",
    "                sent.append(str(n))\n",
    "        sents.append(' '.join(sent))\n",
    "    \n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ec torch.no_grad() makes faster and more efficient\n",
    "def decoding(x, y, encoder, decoder, max_length=40):\n",
    "    decoder = decoder.eval()\n",
    "    loss = 0\n",
    "    with torch.no_grad():   \n",
    "        batch_size = x.size(0)\n",
    "        enc_outputs, hidden = encoder(x)\n",
    "        dec_input = SOS_token*torch.ones(batch_size, 1).long().cuda()  # SOS\n",
    "        decoded_words = []\n",
    "        # ec decide in advance max length. how big are we going to allow the output to be?\n",
    "#         unpacked_out = pad_packed_sequence(enc_outputs, batch_first=True) # FOR ATTENTION\n",
    "        for di in range(1, y.shape[1]):\n",
    "#             output, hidden, attention = decoder(dec_input, hidden, unpacked_out[0]) # FOR ATTENTION\n",
    "            output, hidden = decoder(dec_input, hidden)\n",
    "            pred = output.argmax(dim=1) # ec this is hard prediction (index of right word)\n",
    "            # ec bc we want to keep the prediction around\n",
    "            decoded_words.append(pred.cpu().numpy())\n",
    "            dec_input = output.argmax(dim=1).unsqueeze(1).detach()\n",
    "            yi =  y[:, di]\n",
    "            # without if you will get a None or NA(?) due to divide by zero\n",
    "            if (yi>0).sum() > 0:\n",
    "                # ignoring padding\n",
    "                loss += F.cross_entropy(output, yi, ignore_index = 0, reduction=\"sum\")/(yi>0).sum()\n",
    "\n",
    "        refs = y.cpu().numpy()[:, 1:]\n",
    "        refs = rouge_format(refs)\n",
    "\n",
    "        hyps = np.transpose(decoded_words)\n",
    "        hyps = rouge_format(hyps)\n",
    "        \n",
    "        r = Rouge()\n",
    "        return loss.item(), r.get_scores(hyps, refs, avg=True), np.transpose(decoded_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_rouge_scores(score_list):\n",
    "    combined_rouge = {'rouge-1': {'f': 0, 'p': 0, 'r': 0},\n",
    "                      'rouge-2': {'f': 0, 'p': 0, 'r': 0},\n",
    "                      'rouge-l': {'f': 0, 'p': 0, 'r': 0}}\n",
    "    combined_rouge = pd.DataFrame(combined_rouge)\n",
    "    for score in score_list:\n",
    "        combined_rouge = combined_rouge + pd.DataFrame(score)\n",
    "    \n",
    "    return combined_rouge/len(score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_metrics(encoder, decoder, valid_dl):\n",
    "    rouge_scores = []\n",
    "    \n",
    "    sum_loss = 0\n",
    "    total = 0\n",
    "    for x, y in valid_dl:\n",
    "        x = x.long().cuda()\n",
    "        y = y.long().cuda()\n",
    "        loss, rouge_score, _ = decoding(x, y, encoder, decoder)\n",
    "        sum_loss += loss\n",
    "        total += y.shape[0]\n",
    "        rouge_scores.append(rouge_score)\n",
    "    \n",
    "    return sum_loss/total, combine_rouge_scores(rouge_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(x, y, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "                teacher_forcing_ratio=0.5):\n",
    "    \n",
    "    #two models so two optimizers\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    batch_size = y.size(0)\n",
    "    target_length = y.size(1)\n",
    "\n",
    "    enc_outputs, enc_hidden = encoder(x)\n",
    "\n",
    "    loss = 0\n",
    "    dec_input = y[:,0].unsqueeze(1) # allways SOS (ec always a 1 which is index of start of sequence)\n",
    "    hidden = enc_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    for di in range(1, target_length):\n",
    "#         unpacked_out = pad_packed_sequence(enc_outputs, batch_first=True) # FOR ATTENTION\n",
    "#         output, hidden, attention = decoder(dec_input, hidden, unpacked_out[0]) # FOR ATTENTION\n",
    "        output, hidden = decoder(dec_input, hidden)\n",
    "        # output is prediction, bunch of probabilities (kind of) for each of the words in vocab\n",
    "        yi =  y[:, di]\n",
    "        if (yi>0).sum() > 0:\n",
    "            # ignoring padding\n",
    "            # ec computing loss to ignore index 0, padding gets ignored\n",
    "            # summing so can divide over number of non-zeros that we have\n",
    "            loss += F.cross_entropy(output, yi, ignore_index = 0, reduction=\"sum\")/(yi>0).sum()\n",
    "        if use_teacher_forcing:\n",
    "            # need to decide what is next input\n",
    "            # by teacher forcing, help at the beginning to make things go faster\n",
    "            dec_input = y[:, di].unsqueeze(1)  # Teacher forcing: Feed the target as the next input\n",
    "        else:                \n",
    "            dec_input = output.argmax(dim=1).unsqueeze(1).detach()\n",
    "    # loss depends on all the parameters. Produce gradients for all the paramters\n",
    "    \n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dl, valid_dl, encoder, decoder, enc_optimizer, dec_optimizer, epochs = 10,\n",
    "          teacher_forcing_ratio=0.5):\n",
    "    for i in range(epochs):\n",
    "        total_loss = 0\n",
    "        total = 0\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        for x, y in train_dl:\n",
    "            x = x.long().cuda()\n",
    "            y = y.long().cuda()\n",
    "            loss = train_batch(x, y, encoder, decoder, enc_optimizer, dec_optimizer,\n",
    "                               teacher_forcing_ratio)\n",
    "            total_loss = loss*x.size(0)\n",
    "            total += x.size(0)\n",
    "        val_loss, scores = val_metrics(encoder, decoder, valid_dl)\n",
    "#         if i%2 == 0:\n",
    "        print(\"train loss %.3f val loss %.3f\" % (total_loss/total, val_loss))\n",
    "        print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 300\n",
    "encoder = EncoderRNN(input_size, embedding_dim, hidden_size, emb_matrix).cuda()\n",
    "\n",
    "decoder = DecoderRNN(output_size, embedding_dim, hidden_size, emb_matrix).cuda()\n",
    "\n",
    "\n",
    "# same thing just twice\n",
    "enc_optimizer = optim.Adam(encoder.parameters(), lr=0.01)\n",
    "dec_optimizer = optim.Adam(decoder.parameters(), lr=0.01) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size= 50\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.039 val loss 6.788\n",
      "    rouge-1  rouge-2   rouge-l\n",
      "f  0.067145      0.0  0.037301\n",
      "p  0.382965      0.0  0.382915\n",
      "r  0.036953      0.0  0.036950\n",
      "train loss 0.027 val loss 6.951\n",
      "    rouge-1   rouge-2   rouge-l\n",
      "f  0.080608  0.003460  0.049915\n",
      "p  0.252152  0.009367  0.252152\n",
      "r  0.048339  0.002144  0.048339\n"
     ]
    }
   ],
   "source": [
    "train(train_dl, valid_dl, encoder, decoder, enc_optimizer, dec_optimizer, epochs = 10) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running validation separate from training\n",
    "val_loss, scores = val_metrics(encoder, decoder, valid_dl)\n",
    "print(\"val loss %.3f\" % (val_loss))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving models\n",
    "torch.save(encoder.state_dict(), 'encoder_s2s_wa')\n",
    "torch.save(decoder.state_dict(), 'decoder_s2s_wa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_optimizer = optim.Adam(encoder.parameters(), lr=0.001)\n",
    "dec_optimizer = optim.Adam(decoder.parameters(), lr=0.001) \n",
    "train(encoder, decoder, enc_optimizer, dec_optimizer, epochs = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(encoder, decoder, enc_optimizer, dec_optimizer, epochs = 300, teacher_forcing_ratio=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(encoder, decoder, enc_optimizer, dec_optimizer, epochs = 300, teacher_forcing_ratio=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation\n",
    "==========\n",
    "\n",
    "Evaluation is mostly the same as training, but there are no targets so\n",
    "we simply feed the decoder's predictions back to itself for each step.\n",
    "Every time it predicts a word we add it to the output string, and if it\n",
    "predicts the EOS token we stop there. We also store the decoder's\n",
    "attention outputs for display later.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `model.eval()` will notify all your layers that you are in eval mode, that way, batchnorm or dropout layers will work in eval mode instead of training mode.\n",
    "* `torch.no_grad()` impacts the autograd engine and deactivate it. It will reduce memory usage and speed up computations but you won’t be able to backprop (which you don’t want in an eval script)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(valid_dl)) \n",
    "x = x.long().cuda()\n",
    "y = y.long().cuda()\n",
    "\n",
    "loss, _ = decoding(x, y, encoder, decoder)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training example predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=5\n",
    "train_dl_2 = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "x, y = next(iter(train_dl_2)) \n",
    "x = x.long().cuda()\n",
    "y = y.long().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate random sentences from the training set and print out the\n",
    "input, target, and output to make some subjective quality judgements:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(x, y, encoder, decoder, rouge):\n",
    "    _, _, decoded_words = decoding(x, y, l, encoder, decoder)\n",
    "    for i in range(x.shape[0]):\n",
    "        xi = x[i].cpu().numpy()\n",
    "        yi = y[i].cpu().numpy()\n",
    "        y_hat = decoded_words[i]\n",
    "        x_sent = ' '.join([inv_vocab[t] for t in xi if t > 3])\n",
    "        y_sent = ' '.join([inv_vocab[t] for t in yi if t > 3])\n",
    "        y_hat_sent = ' '.join([inv_vocab[t] for t in y_hat if t > 3])\n",
    "        print('=', y_sent)\n",
    "        print('<', y_hat_sent)\n",
    "#         if len(yi) > len(y_hat):\n",
    "#              y_hat_sent = y_hat_sent + ' <unk>' * (len(yi) - len(y_hat))\n",
    "#         elif len(yi) < len(y_hat):\n",
    "#              y_sent = y_sent + ' <unk>' * (len(y_hat) - len(yi))\n",
    "#         print(rouge.get_scores(y_hat_sent, y_sent)[0]['rouge-1'])\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rouge = Rouge()\n",
    "print_results(x, y, l, encoder, decoder, rouge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rouge Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation example predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=10\n",
    "valid_dl_2 = DataLoader(valid_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "x, y = next(iter(valid_dl_2)) \n",
    "x = x.long().cuda()\n",
    "y = y.long().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(x, y, l, encoder, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "-  Replace the embeddings with pre-trained word embeddings. Here are word embeddings for various languages.\n",
    "\n",
    "https://fasttext.cc/docs/en/crawl-vectors.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credits\n",
    "The original notebook was written by Sean Robertson <https://github.com/spro/practical-pytorch>_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
