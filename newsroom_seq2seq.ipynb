{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Sequence to Sequence - Article Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T03:04:22.643999Z",
     "start_time": "2019-06-21T03:04:22.633771Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T04:37:35.830305Z",
     "start_time": "2019-06-21T04:37:35.498103Z"
    }
   },
   "outputs": [],
   "source": [
    "path = './'\n",
    "vocab = pickle.load(open(path + 'vocab.pkl', \"rb\" ))\n",
    "inv_vocab = pickle.load(open(path + 'inv_vocab.pkl', \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-21T04:37:59.071Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, ...</td>\n",
       "      <td>[1, 148, 17, 149, 150, 112, 151, 136, 60, 79, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 742, 743, 11, 646, 307, 744, 132, 596, 745...</td>\n",
       "      <td>[1, 11, 762, 763, 764, 769, 770, 771, 272, 772...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 910, 940, 840, 941, 132, 942, 569, 943, 94...</td>\n",
       "      <td>[1, 11, 954, 947, 948, 949, 950, 72, 951, 1027...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 136, 1153, 1154, 910, 1155, 1156, 1157, 11...</td>\n",
       "      <td>[1, 910, 1155, 1156, 1157, 1158, 265, 167, 422...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 1413, 132, 1414, 1415, 1416, 1417, 1418, 3...</td>\n",
       "      <td>[1, 1510, 1435, 1427, 1428, 1511, 1413, 17, 15...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  [1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, ...   \n",
       "1  [1, 742, 743, 11, 646, 307, 744, 132, 596, 745...   \n",
       "2  [1, 910, 940, 840, 941, 132, 942, 569, 943, 94...   \n",
       "3  [1, 136, 1153, 1154, 910, 1155, 1156, 1157, 11...   \n",
       "4  [1, 1413, 132, 1414, 1415, 1416, 1417, 1418, 3...   \n",
       "\n",
       "                                             summary  \n",
       "0  [1, 148, 17, 149, 150, 112, 151, 136, 60, 79, ...  \n",
       "1  [1, 11, 762, 763, 764, 769, 770, 771, 272, 772...  \n",
       "2  [1, 11, 954, 947, 948, 949, 950, 72, 951, 1027...  \n",
       "3  [1, 910, 1155, 1156, 1157, 1158, 265, 167, 422...  \n",
       "4  [1, 1510, 1435, 1427, 1428, 1511, 1413, 17, 15...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './'\n",
    "train_df = pickle.load(open(path + 'train_df.pkl', \"rb\"))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './'\n",
    "dev_df = pickle.load(open(path + 'dev_df.pkl', \"rb\"))\n",
    "dev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T04:01:42.896751Z",
     "start_time": "2019-06-21T04:01:42.892838Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_df.text[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-20T20:59:18.608736Z",
     "start_time": "2019-06-20T20:59:18.605224Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27578\n",
      "bro\n"
     ]
    }
   ],
   "source": [
    "print(vocab['bro'])\n",
    "print(inv_vocab[27578])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-20T22:54:59.668354Z",
     "start_time": "2019-06-20T22:54:59.658220Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, ...</td>\n",
       "      <td>[1, 148, 17, 149, 150, 112, 151, 136, 60, 79, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 742, 743, 11, 646, 307, 744, 132, 596, 745...</td>\n",
       "      <td>[1, 11, 762, 763, 764, 769, 770, 771, 272, 772...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 910, 940, 840, 941, 132, 942, 569, 943, 94...</td>\n",
       "      <td>[1, 11, 954, 947, 948, 949, 950, 72, 951, 1027...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 136, 1153, 1154, 910, 1155, 1156, 1157, 11...</td>\n",
       "      <td>[1, 910, 1155, 1156, 1157, 1158, 265, 167, 422...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 1413, 132, 1414, 1415, 1416, 1417, 1418, 3...</td>\n",
       "      <td>[1, 1510, 1435, 1427, 1428, 1511, 1413, 17, 15...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  [1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, ...   \n",
       "1  [1, 742, 743, 11, 646, 307, 744, 132, 596, 745...   \n",
       "2  [1, 910, 940, 840, 941, 132, 942, 569, 943, 94...   \n",
       "3  [1, 136, 1153, 1154, 910, 1155, 1156, 1157, 11...   \n",
       "4  [1, 1413, 132, 1414, 1415, 1416, 1417, 1418, 3...   \n",
       "\n",
       "                                             summary  \n",
       "0  [1, 148, 17, 149, 150, 112, 151, 136, 60, 79, ...  \n",
       "1  [1, 11, 762, 763, 764, 769, 770, 771, 272, 772...  \n",
       "2  [1, 11, 954, 947, 948, 949, 950, 72, 951, 1027...  \n",
       "3  [1, 910, 1155, 1156, 1157, 1158, 265, 167, 422...  \n",
       "4  [1, 1510, 1435, 1427, 1428, 1511, 1413, 17, 15...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T04:22:42.287768Z",
     "start_time": "2019-06-21T04:22:42.259456Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 4., 6.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2, 4, 6]\n",
    "torch.Tensor(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T04:30:15.196743Z",
     "start_time": "2019-06-21T04:30:14.980487Z"
    }
   },
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    \"\"\"Creates mini-batch tensors from the list of tuples (sentences, labels).\n",
    "    \n",
    "    Need custom collate_fn because merging sequences (including padding) is not \n",
    "    supported in default. Sequences are padded to the maximum length of mini-batch \n",
    "    sequences (dynamic padding).\n",
    "    \n",
    "    Args:\n",
    "        data: list of tuple (article, summary). \n",
    "            - each is list of word indices of variable length\n",
    "    Returns:\n",
    "        packed_batch: (PackedSequence), see torch.nn.utils.rnn.pack_padded_sequence\n",
    "        sencences: torch tensor of shape (batch_size, max_len).\n",
    "        labels: torch tensor of shape (batch_size, 1).\n",
    "        lengths: list; valid length for each padded sentence. \n",
    "    \"\"\"\n",
    "    # Sort a data list by sentences length (descending order).\n",
    "    data.sort(key=lambda x: len(x[0]), reverse=True)\n",
    "    articles, summaries = zip(*data)\n",
    "        \n",
    "    # Merge sentences\n",
    "    lengths1 = [len(s) for s in articles]\n",
    "    lengths2 = [len(s) for s in summaries]\n",
    "   \n",
    "    arts = torch.zeros(len(articles), max(lengths1)).long()\n",
    "    summs = torch.zeros(len(summaries), max(lengths2)).long()\n",
    "    \n",
    "    for i, a in enumerate(articles):\n",
    "        l = lengths1[i]\n",
    "        arts[i, -l:] = torch.Tensor(a[:l])\n",
    "        \n",
    "    for i, s in enumerate(summaries):\n",
    "        l = lengths2[i]\n",
    "        summs[i, :l] = torch.Tensor(s[:l])\n",
    "    \n",
    "    return arts, summs, lengths1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T04:30:15.335690Z",
     "start_time": "2019-06-21T04:30:15.331289Z"
    }
   },
   "outputs": [],
   "source": [
    "class SummarizationDataset(Dataset):\n",
    "    def __init__(self, df): #pairs, input_lang, output_lang):\n",
    "        self.df = df\n",
    "        self.article = df.text.values\n",
    "        self.summary = df.summary.values\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.article)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.article[idx]\n",
    "        y = self.summary[idx]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T04:30:15.630665Z",
     "start_time": "2019-06-21T04:30:15.628566Z"
    }
   },
   "outputs": [],
   "source": [
    "# import ast\n",
    "# df['text'].apply(lambda x: ast.literal_eval(x))\n",
    "# df['summary'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(count    995041.000000\n",
       " mean        587.993332\n",
       " std         764.028830\n",
       " min           2.000000\n",
       " 25%         246.000000\n",
       " 50%         467.000000\n",
       " 75%         751.000000\n",
       " max      102471.000000\n",
       " Name: text, dtype: float64, count    995041.000000\n",
       " mean         25.583946\n",
       " std          23.694143\n",
       " min           2.000000\n",
       " 25%          16.000000\n",
       " 50%          22.000000\n",
       " 75%          28.000000\n",
       " max        5678.000000\n",
       " Name: summary, dtype: float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_lens = train_df.text.map(lambda x: len(x))\n",
    "summary_lens = train_df.summary.map(lambda x: len(x))\n",
    "text_lens.describe(), summary_lens.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55508, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df[(text_lens > 246) &(text_lens < 751) & (summary_lens < 28) & (summary_lens > 16)]\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T04:30:16.331393Z",
     "start_time": "2019-06-21T04:30:16.328775Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds = SummarizationDataset(train_df)\n",
    "valid_ds = SummarizationDataset(dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T04:30:16.517551Z",
     "start_time": "2019-06-21T04:30:16.514012Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 6579,\n",
       " 106,\n",
       " 1276,\n",
       " 1302,\n",
       " 103,\n",
       " 3992,\n",
       " 3719,\n",
       " 4567,\n",
       " 132,\n",
       " 12973,\n",
       " 2849,\n",
       " 2129,\n",
       " 4991,\n",
       " 14,\n",
       " 9,\n",
       " 3385,\n",
       " 3704,\n",
       " 3294,\n",
       " 2]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T04:30:17.008644Z",
     "start_time": "2019-06-21T04:30:16.990744Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size=5\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T04:30:17.492115Z",
     "start_time": "2019-06-21T04:30:17.428387Z"
    }
   },
   "outputs": [],
   "source": [
    "arts, summs, l = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T04:30:18.217978Z",
     "start_time": "2019-06-21T04:30:18.214074Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 433]), torch.Size([5, 21]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arts.shape, summs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Seq2Seq Model\n",
    "\n",
    "A Recurrent Neural Network, or RNN, is a network that operates on a\n",
    "sequence and uses its own output as input for subsequent steps.\n",
    "\n",
    "A `Sequence to Sequence network <https://arxiv.org/abs/1409.3215>`__, or\n",
    "seq2seq network, or `Encoder Decoder\n",
    "network <https://arxiv.org/pdf/1406.1078v3.pdf>`__, is a model\n",
    "consisting of two RNNs called the encoder and decoder. The encoder reads\n",
    "an input sequence and outputs a single vector, and the decoder reads\n",
    "that vector to produce an output sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Encoder\n",
    "\n",
    "The encoder of a seq2seq network is a RNN that outputs some value for\n",
    "every word from the input sentence. For every input word the encoder\n",
    "outputs a vector and a hidden state, and uses the hidden state for the\n",
    "next input word.\n",
    "\n",
    "![](imgs/encoder-network.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "word2vec_path = '~/GoogleNews-vectors-negative300.bin'\n",
    "word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_matrix(word_vecs, inv_vocab, D=300):\n",
    "    \"\"\"Creates embedding matrix from word vectors. \"\"\"\n",
    "    V = len(inv_vocab)\n",
    "    W = np.random.randn(V, D)\n",
    "\n",
    "    for i in range(V):\n",
    "        if inv_vocab[i] in word_vecs:\n",
    "            W[i] = word_vecs[inv_vocab[i]]\n",
    "\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00402832, -0.24707031,  0.09814453, ...,  0.1640625 ,\n",
       "         0.24023438,  0.6875    ],\n",
       "       [-0.19433594, -0.05932617, -0.18066406, ..., -0.12988281,\n",
       "        -0.15527344,  0.14941406],\n",
       "       [-0.15039062, -0.03063965,  0.02770996, ...,  0.11132812,\n",
       "         0.06225586,  0.04003906],\n",
       "       ...,\n",
       "       [ 0.04492188,  0.05664062,  0.09863281, ..., -0.03173828,\n",
       "         0.125     ,  0.05371094],\n",
       "       [-0.11425781,  0.12109375, -0.04418945, ...,  0.10351562,\n",
       "         0.08203125,  0.08154297],\n",
       "       [ 0.0402832 , -0.03149414, -0.15332031, ..., -0.00570679,\n",
       "        -0.06396484, -0.15625   ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = 300\n",
    "\n",
    "emb_matrix = create_embedding_matrix(word2vec, inv_vocab, embedding_dim)\n",
    "emb_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T04:34:29.831839Z",
     "start_time": "2019-06-21T04:34:29.826612Z"
    }
   },
   "outputs": [],
   "source": [
    "# encoder is RNN\n",
    "# input size is number of words in french vocabulary\n",
    "# choose hidden size for ...\n",
    "# embedding layer, gru , and dropout\n",
    "# get output and hidden, output both of them\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, embedding_matrix):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.embeddings.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
    "        self.embeddings.weight.requires_grad = False\n",
    "        self.gru = nn.GRU(hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        x = self.embeddings(x)\n",
    "        #x = self.dropout(x)\n",
    "        pack = pack_padded_sequence(x, lengths, batch_first=True)\n",
    "        output, hidden = self.gru(pack)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T04:34:30.441996Z",
     "start_time": "2019-06-21T04:34:30.378714Z"
    }
   },
   "outputs": [],
   "source": [
    "x, y, l = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T04:34:30.670602Z",
     "start_time": "2019-06-21T04:34:30.664677Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[    1,   496,   132,  ...,  1053,  6362,     2],\n",
       "         [    0,     1,   136,  ...,  1769,   233,     2],\n",
       "         [    0,     0,     0,  ...,  3689, 22253,     2],\n",
       "         [    0,     0,     0,  ...,    22,  8303,     2],\n",
       "         [    0,     0,     0,  ...,   272,  3321,     2]]),\n",
       " tensor([[    1,   496,   132,    38,   264,  2841, 32027,  2086,  7811,  7847,\n",
       "           1423, 26012, 32284,    22, 27431, 30362,     2,     0,     0,     0,\n",
       "              0],\n",
       "         [    1,  3421, 21456, 22391, 23444,  3060,    93,  1431,  5030,   768,\n",
       "            525,   576,  2776,   551,   261,  3658,     8,  2772,   106,  2853,\n",
       "              2],\n",
       "         [    1,    11, 16077,  6768,  3475,  6778,    72,  3935, 10654,  6624,\n",
       "             86,  2554,  4950,  1420,  1756,   181,     2,     0,     0,     0,\n",
       "              0],\n",
       "         [    1, 17258,  8170,  2144, 14644,   497,   231,   264,   209,     8,\n",
       "              9, 29466,    58, 11876,  1178, 43904,    17,    41,    10,   538,\n",
       "              2],\n",
       "         [    1,    30,  2448,  5655,  3797,  4764,  1314,  1252,  3977, 13705,\n",
       "            964,    17,    11,  7229,   544,   113,   227,  5558,  2481,   159,\n",
       "              2]]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T04:34:31.452711Z",
     "start_time": "2019-06-21T04:34:31.010817Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "hidden_size = 300\n",
    "encoder = EncoderRNN(vocab_size, embedding_dim, hidden_size, emb_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T04:34:32.214942Z",
     "start_time": "2019-06-21T04:34:31.454466Z"
    }
   },
   "outputs": [],
   "source": [
    "enc_outputs, enc_hidden = encoder(x.long(), l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T04:34:36.445011Z",
     "start_time": "2019-06-21T04:34:36.436416Z"
    }
   },
   "outputs": [],
   "source": [
    "# enc_outputs.shape, enc_hidden.shape\n",
    "# what is size of encoder output and encoder hidden\n",
    "# 5 is batch size, 17 is max length\n",
    "# 5 is last state of each of 5 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T04:35:20.535689Z",
     "start_time": "2019-06-21T04:35:20.521276Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[ 0.0384,  0.0521,  0.0305,  ...,  0.0287,  0.0760,  0.0350],\n",
       "        [-0.0445, -0.0282,  0.0371,  ..., -0.0816, -0.0561, -0.1053],\n",
       "        [-0.0445, -0.0282,  0.0371,  ..., -0.0816, -0.0561, -0.1053],\n",
       "        ...,\n",
       "        [ 0.0559,  0.0291,  0.0178,  ...,  0.0553, -0.0208, -0.1013],\n",
       "        [ 0.0617,  0.0107, -0.0138,  ..., -0.0115,  0.0139, -0.0077],\n",
       "        [ 0.0652,  0.0491,  0.0828,  ...,  0.0892,  0.1814, -0.1452]],\n",
       "       grad_fn=<CatBackward>), batch_sizes=tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The  Decoder\n",
    "   -----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder has embedding layer, gru, \n",
    "# output size is size of english vocabulary\n",
    "# loss function is trying to produce \n",
    "# output is taking the hidden state of decoder,\n",
    "# going through linear layer to try to produce \"the\"\n",
    "# run the decoder (GRU) word by word, because we need \"the\" to predict\n",
    "# next word, \"poor\"\n",
    "# sometimes we use the prediction or sometimes we use the actual\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, output_size, hidden_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size, padding_idx=0)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        embedded = self.embedding(x)\n",
    "        embedded = self.dropout(embedded)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        output = self.out(hidden[-1]) # output is a function of the hidden, what we are comparing to the y\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = vocab_size\n",
    "hidden_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SOS_token = 1\n",
    "batch_size = y.size(0)\n",
    "decoder_input = SOS_token*torch.ones(batch_size,1).long()\n",
    "decoder_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = DecoderRNN(output_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, hidden = decoder(decoder_input, enc_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 5, 300]), torch.Size([5, 140326]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden.shape, output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training\n",
    "========"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(x, y, l1, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "                teacher_forcing_ratio=0.5):\n",
    "    \n",
    "    #two models so two optimizers\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    batch_size = y.size(0)\n",
    "    target_length = y.size(1)\n",
    "\n",
    "    enc_outputs, enc_hidden = encoder(x, l1)\n",
    "\n",
    "    loss = 0\n",
    "    dec_input = y[:,0].unsqueeze(1) # allways SOS (ec always a 1 which is index of start of sequence)\n",
    "    hidden = enc_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    for di in range(1, target_length):\n",
    "        output, hidden = decoder(dec_input, hidden) # getting new hidden and output\n",
    "        # output is prediction, bunch of probabilities (kind of) for each of the words in vocab\n",
    "        yi =  y[:, di]\n",
    "        if (yi>0).sum() > 0:\n",
    "            # ignoring padding\n",
    "            # ec computing loss to ignore index 0, padding gets ignored\n",
    "            # summing so can divide over number of non-zeros that we have\n",
    "            loss += F.cross_entropy(output, yi, ignore_index = 0, reduction=\"sum\")/(yi>0).sum()\n",
    "        if use_teacher_forcing:\n",
    "            # need to decide what is next input\n",
    "            # by teacher forcing, help at the beginning to make things go faster\n",
    "            dec_input = y[:, di].unsqueeze(1)  # Teacher forcing: Feed the target as the next input\n",
    "        else:                \n",
    "            dec_input = output.argmax(dim=1).unsqueeze(1).detach()\n",
    "    # loss depends on all the parameters. Produce gradients for all the paramters\n",
    "    \n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(encoder, decoder, enc_optimizer, dec_optimizer, epochs = 10,\n",
    "          teacher_forcing_ratio=0.5):\n",
    "    for i in range(epochs):\n",
    "        total_loss = 0\n",
    "        total = 0\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "#        for x, y in train_dl:\n",
    "        for x, y, l1 in train_dl:\n",
    "            x = x.long().cuda()\n",
    "            y = y.long().cuda()\n",
    "            loss = train_batch(x, y, l1, encoder, decoder, enc_optimizer, dec_optimizer,\n",
    "                               teacher_forcing_ratio)\n",
    "            total_loss = loss*x.size(0)\n",
    "            total += x.size(0)\n",
    "        if i%2 == 0:\n",
    "            print(\"train loss %.3f\" % (total_loss / total))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = vocab_size\n",
    "output_size = vocab_size\n",
    "hidden_size = 300\n",
    "encoder = EncoderRNN(vocab_size, embedding_dim, hidden_size, emb_matrix).cuda()\n",
    "decoder = DecoderRNN(output_size, hidden_size).cuda()\n",
    "# same thing just twice\n",
    "enc_optimizer = optim.Adam(encoder.parameters(), lr=0.01)\n",
    "dec_optimizer = optim.Adam(decoder.parameters(), lr=0.01) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size= 70\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, collate_fn=collate_fn, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.083\n"
     ]
    }
   ],
   "source": [
    "train(encoder, decoder, enc_optimizer, dec_optimizer, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder.state_dict(), 'encoder')\n",
    "torch.save(decoder.state_dict(), 'decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_optimizer = optim.Adam(encoder.parameters(), lr=0.001)\n",
    "dec_optimizer = optim.Adam(decoder.parameters(), lr=0.001) \n",
    "train(encoder, decoder, enc_optimizer, dec_optimizer, epochs = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(encoder, decoder, enc_optimizer, dec_optimizer, epochs = 300, teacher_forcing_ratio=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(encoder, decoder, enc_optimizer, dec_optimizer, epochs = 300, teacher_forcing_ratio=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation\n",
    "==========\n",
    "\n",
    "Evaluation is mostly the same as training, but there are no targets so\n",
    "we simply feed the decoder's predictions back to itself for each step.\n",
    "Every time it predicts a word we add it to the output string, and if it\n",
    "predicts the EOS token we stop there. We also store the decoder's\n",
    "attention outputs for display later.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `model.eval()` will notify all your layers that you are in eval mode, that way, batchnorm or dropout layers will work in eval mode instead of training mode.\n",
    "* `torch.no_grad()` impacts the autograd engine and deactivate it. It will reduce memory usage and speed up computations but you won’t be able to backprop (which you don’t want in an eval script)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ec torch.no_grad() makes faster and more efficient\n",
    "def decoding(x, y, l, encoder, decoder, max_length=50):\n",
    "    decoder = decoder.eval()\n",
    "    loss = 0\n",
    "    with torch.no_grad():   \n",
    "        batch_size = x.size(0)\n",
    "        enc_outputs, hidden = encoder(x, l)\n",
    "        dec_input = SOS_token*torch.ones(batch_size, 1).long().cuda()  # SOS\n",
    "        decoded_words = []\n",
    "        # ec decide in advance max length. how big are we going to allow the output to be?\n",
    "        for di in range(1, y.shape[1]):\n",
    "            output, hidden = decoder(dec_input, hidden)\n",
    "            pred = output.argmax(dim=1) # ec this is hard prediction (index of right word)\n",
    "            # ec bc we want to keep the prediction around\n",
    "            decoded_words.append(pred.cpu().numpy())\n",
    "            dec_input = output.argmax(dim=1).unsqueeze(1).detach()\n",
    "            yi =  y[:, di]\n",
    "            # without if you will get a None or NA(?) due to divide by zero\n",
    "            if (yi>0).sum() > 0:\n",
    "                # ignoring padding\n",
    "                loss += F.cross_entropy(\n",
    "                    output, yi, ignore_index = 0, reduction=\"sum\")/(yi>0).sum()\n",
    "        return loss.item()/batch_size, np.transpose(decoded_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(valid_dl)) \n",
    "x = x.long().cuda()\n",
    "y = y.long().cuda()\n",
    "\n",
    "loss, _ = decoding(x, y, encoder, decoder)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training example predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=5\n",
    "train_dl_2 = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "x, y, l = next(iter(train_dl_2)) \n",
    "x = x.long().cuda()\n",
    "y = y.long().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate random sentences from the training set and print out the\n",
    "input, target, and output to make some subjective quality judgements:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(x, y, l, encoder, decoder, rouge):\n",
    "    _, decoded_words = decoding(x, y, l, encoder, decoder)\n",
    "    for i in range(x.shape[0]):\n",
    "        xi = x[i].cpu().numpy()\n",
    "        yi = y[i].cpu().numpy()\n",
    "        y_hat = decoded_words[i]\n",
    "        x_sent = ' '.join([inv_vocab[t] for t in xi if t > 3])\n",
    "        y_sent = ' '.join([inv_vocab[t] for t in yi if t > 3])\n",
    "        y_hat_sent = ' '.join([inv_vocab[t] for t in y_hat if t > 3])\n",
    "#         print('>', x_sent)\n",
    "        print('=', y_sent)\n",
    "        print('<', y_hat_sent)\n",
    "        if len(yi) > len(y_hat):\n",
    "             y_hat_sent = y_hat_sent + ' <unk>' * (len(yi) - len(y_hat))\n",
    "        elif len(yi) < len(y_hat):\n",
    "             y_sent = y_sent + ' <unk>' * (len(y_hat) - len(yi))\n",
    "        print(rouge.get_scores(y_hat_sent, y_sent)[0]['rouge-1'])\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= america made renewed attempt talk up its flagging economy on tuesday despite raft disappointing economic data\n",
      "< the obama the the the the the the the the the the\n",
      "{'f': 0.0, 'p': 0.0, 'r': 0.0}\n",
      "\n",
      "= royal sister princess charlotte is causing global fashion frenzy after her adorable tour wardrobe sells out fast\n",
      "< the prince is the e princess the the the the the the the\n",
      "{'f': 0.17391303962192828, 'p': 0.3333333333333333, 'r': 0.11764705882352941}\n",
      "\n",
      "= the mexican authorities say mart nez planned the killings dozens central south americans hauled from buses trucks heading north\n",
      "< the hauled nez nez nez nez nez nez nez nez nez nez nez nez nez nez nez nez nez nez\n",
      "{'f': 0.2727272697520661, 'p': 0.75, 'r': 0.16666666666666666}\n",
      "\n",
      "= the murder in west jerusalem four men at prayer including three rabbis is tragedy for all israelis palestinians\n",
      "< the square men are in the men in rifles the men in\n",
      "{'f': 0.23999999596800003, 'p': 0.42857142857142855, 'r': 0.16666666666666666}\n",
      "\n",
      "= obama rides high in polls despite fading gop support the oval tracking the obama presidency\n",
      "< the obama will address biggies address the oval tracking the obama presidency on politics covering congress governors the election com\n",
      "{'f': 0.34482758126040436, 'p': 0.3125, 'r': 0.38461538461538464}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rouge = Rouge()\n",
    "print_results(x, y, l, encoder, decoder, rouge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rouge Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation example predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=10\n",
    "valid_dl_2 = DataLoader(valid_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "x, y = next(iter(valid_dl_2)) \n",
    "x = x.long().cuda()\n",
    "y = y.long().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(x, y, l, encoder, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "-  Replace the embeddings with pre-trained word embeddings. Here are word embeddings for various languages.\n",
    "\n",
    "https://fasttext.cc/docs/en/crawl-vectors.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credits\n",
    "The original notebook was written by Sean Robertson <https://github.com/spro/practical-pytorch>_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
